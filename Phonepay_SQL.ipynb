{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bac0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f5f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract JSON â†’ DataFrames\n",
    "\n",
    "def agg_insur_data():\n",
    "    path_1=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\aggregated\\\\insurance\\\\country\\\\india\\\\state\\\\\"\n",
    "    agg_trans_list=os.listdir(path_1)\n",
    "    column_1={'State':[], 'Year':[],'quarter':[],'Transaction_type':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "    for state in agg_trans_list:\n",
    "        path_states=path_1+state+\"/\"\n",
    "        for year in os.listdir(path_states):\n",
    "            path_year=path_states+year+\"/\"\n",
    "            for file in os.listdir(path_year):\n",
    "                path_file=path_year+file\n",
    "                data=open(path_file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"transactionData\"]:\n",
    "                    Name=z[\"name\"]\n",
    "                    count=z['paymentInstruments'][0]['count']\n",
    "                    amount=z['paymentInstruments'][0]['amount']\n",
    "                    column_1[\"State\"].append(state)\n",
    "                    column_1[\"Year\"].append(year)\n",
    "                    column_1[\"Transaction_type\"].append(Name)\n",
    "                    column_1[\"Transaction_count\"].append(count)\n",
    "                    column_1[\"Transaction_amount\"].append(amount)\n",
    "                    column_1[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_1=pd.DataFrame(column_1)\n",
    "    df_1[\"State\"]=df_1[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_1[\"State\"]=df_1[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_1[\"State\"]=df_1[\"State\"].str.title()\n",
    "    df_1[\"State\"]=df_1[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_1\n",
    "\n",
    "def agg_trans_data():\n",
    "    path_2=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\aggregated\\\\transaction\\\\country\\\\india\\\\state\\\\\"\n",
    "    agg_trans_list=os.listdir(path_2)\n",
    "    column_2={'State':[], 'Year':[],'quarter':[],'Transaction_type':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "    for state in agg_trans_list:\n",
    "        path_states=path_2+state+\"/\"\n",
    "        for year in os.listdir(path_states):\n",
    "            path_year=path_states+year+\"/\"\n",
    "            for file in os.listdir(path_year):\n",
    "                path_file=path_year+file\n",
    "                data=open(path_file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"transactionData\"]:\n",
    "                    Name=z[\"name\"]\n",
    "                    count=z['paymentInstruments'][0]['count']\n",
    "                    amount=z['paymentInstruments'][0]['amount']\n",
    "                    column_2[\"State\"].append(state)\n",
    "                    column_2[\"Year\"].append(year)\n",
    "                    column_2[\"Transaction_type\"].append(Name)\n",
    "                    column_2[\"Transaction_count\"].append(count)\n",
    "                    column_2[\"Transaction_amount\"].append(amount)\n",
    "                    column_2[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_2=pd.DataFrame(column_2)\n",
    "    df_2[\"State\"]=df_2[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_2[\"State\"]=df_2[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_2[\"State\"]=df_2[\"State\"].str.title()\n",
    "    df_2[\"State\"]=df_2[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_2\n",
    "\n",
    "def agg_user_data():\n",
    "    path_3=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\aggregated\\\\user\\\\country\\\\india\\\\state\\\\\"\n",
    "    column_3={'State':[], 'Year':[],'quarter':[],'user_Brand':[], 'user_count':[], 'user_percentage':[]}\n",
    "    for state in os.listdir(path_3):\n",
    "        for year in os.listdir(path_3+state+\"/\"):\n",
    "            for file in os.listdir(path_3+state+\"/\"+year+\"/\"):\n",
    "                data=open(path_3+state+\"/\"+year+\"/\"+file,\"r\")\n",
    "                D=json.load(data)\n",
    "                try:\n",
    "                    for z in D[\"data\"][\"usersByDevice\"]:\n",
    "                        column_3[\"State\"].append(state)\n",
    "                        column_3[\"Year\"].append(year)\n",
    "                        column_3[\"user_Brand\"].append(z[\"brand\"])\n",
    "                        column_3[\"user_count\"].append(z[\"count\"])\n",
    "                        column_3[\"user_percentage\"].append(z[\"percentage\"])\n",
    "                        column_3[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "                except:\n",
    "                    pass\n",
    "    df_3=pd.DataFrame(column_3)\n",
    "    df_3[\"State\"]=df_3[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_3[\"State\"]=df_3[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_3[\"State\"]=df_3[\"State\"].str.title()\n",
    "    df_3[\"State\"]=df_3[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_3\n",
    "\n",
    "def map_insur_data():\n",
    "    path_4=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\map\\\\insurance\\\\hover\\\\country\\\\india\\\\state\\\\\"\n",
    "    column_4={'State':[],'Year':[], 'District':[], 'quarter':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "    for state in os.listdir(path_4):\n",
    "        for year in os.listdir(path_4+state+\"/\"):\n",
    "            for file in os.listdir(path_4+state+\"/\"+year+\"/\"):\n",
    "                data=open(path_4+state+\"/\"+year+\"/\"+file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"hoverDataList\"]:\n",
    "                    column_4[\"State\"].append(state)\n",
    "                    column_4[\"Year\"].append(year)\n",
    "                    column_4[\"District\"].append(z[\"name\"])\n",
    "                    column_4[\"Transaction_count\"].append(z[\"metric\"][0][\"count\"])\n",
    "                    column_4[\"Transaction_amount\"].append(z[\"metric\"][0][\"amount\"])\n",
    "                    column_4[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_4=pd.DataFrame(column_4)\n",
    "    df_4[\"State\"]=df_4[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_4[\"State\"]=df_4[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_4[\"State\"]=df_4[\"State\"].str.title()\n",
    "    df_4[\"State\"]=df_4[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_4\n",
    "\n",
    "def map_trans_data():\n",
    "    path_5=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\map\\\\transaction\\\\hover\\\\country\\\\india\\\\state\\\\\"\n",
    "    column_5={'State':[],'Year':[], 'District':[], 'quarter':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "    for state in os.listdir(path_5):\n",
    "        for year in os.listdir(path_5+state+\"/\"):\n",
    "            for file in os.listdir(path_5+state+\"/\"+year+\"/\"):\n",
    "                data=open(path_5+state+\"/\"+year+\"/\"+file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"hoverDataList\"]:\n",
    "                    column_5[\"State\"].append(state)\n",
    "                    column_5[\"Year\"].append(year)\n",
    "                    column_5[\"District\"].append(z[\"name\"])\n",
    "                    column_5[\"Transaction_count\"].append(z[\"metric\"][0][\"count\"])\n",
    "                    column_5[\"Transaction_amount\"].append(z[\"metric\"][0][\"amount\"])\n",
    "                    column_5[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_5=pd.DataFrame(column_5)\n",
    "    df_5[\"State\"]=df_5[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_5[\"State\"]=df_5[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_5[\"State\"]=df_5[\"State\"].str.title()\n",
    "    df_5[\"State\"]=df_5[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_5\n",
    "\n",
    "def map_user_data():\n",
    "    path_6=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\map\\\\user\\\\hover\\\\country\\\\india\\\\state\\\\\"\n",
    "    column_6={'State':[],'District':[],'Year':[],'quarter':[],'Registered_Users':[],'App_Opens':[]}\n",
    "    for state in os.listdir(path_6):\n",
    "        for year in os.listdir(path_6+state+\"/\"):\n",
    "            for file in os.listdir(path_6+state+\"/\"+year+\"/\"):\n",
    "                data=open(path_6+state+\"/\"+year+\"/\"+file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"hoverData\"].items():\n",
    "                    column_6[\"State\"].append(state)\n",
    "                    column_6[\"Year\"].append(year)\n",
    "                    column_6[\"District\"].append(z[0])\n",
    "                    column_6[\"Registered_Users\"].append(z[1][\"registeredUsers\"])\n",
    "                    column_6[\"App_Opens\"].append(z[1][\"appOpens\"])\n",
    "                    column_6[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_6=pd.DataFrame(column_6)\n",
    "    df_6[\"State\"]=df_6[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_6[\"State\"]=df_6[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_6[\"State\"]=df_6[\"State\"].str.title()\n",
    "    df_6[\"State\"]=df_6[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_6\n",
    "\n",
    "def top_insur_data():\n",
    "    path_7=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\top\\\\insurance\\\\country\\\\india\\\\state\\\\\"\n",
    "    column_7= {'State':[],'Pincode':[],'Year':[],'quarter':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "    for state in os.listdir(path_7):\n",
    "        for year in os.listdir(path_7+state+\"/\"):\n",
    "            for file in os.listdir(path_7+state+\"/\"+year+\"/\"):\n",
    "                data=open(path_7+state+\"/\"+year+\"/\"+file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"pincodes\"]:\n",
    "                    column_7[\"State\"].append(state)\n",
    "                    column_7[\"Year\"].append(year)\n",
    "                    column_7[\"Pincode\"].append(z[\"entityName\"])\n",
    "                    column_7[\"Transaction_count\"].append(z[\"metric\"][\"count\"])\n",
    "                    column_7[\"Transaction_amount\"].append(z[\"metric\"][\"amount\"])\n",
    "                    column_7[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_7=pd.DataFrame(column_7)\n",
    "    df_7[\"State\"]=df_7[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_7[\"State\"]=df_7[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_7[\"State\"]=df_7[\"State\"].str.title()\n",
    "    df_7[\"State\"]=df_7[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_7\n",
    "\n",
    "def top_trans_data():\n",
    "    path_8=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\top\\\\transaction\\\\country\\\\india\\\\state\\\\\"\n",
    "    column_8= {'State':[],'Pincode':[],'Year':[],'quarter':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "    for state in os.listdir(path_8):\n",
    "        for year in os.listdir(path_8+state+\"/\"):\n",
    "            for file in os.listdir(path_8+state+\"/\"+year+\"/\"):\n",
    "                data=open(path_8+state+\"/\"+year+\"/\"+file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"pincodes\"]:\n",
    "                    column_8[\"State\"].append(state)\n",
    "                    column_8[\"Year\"].append(year)\n",
    "                    column_8[\"Pincode\"].append(z[\"entityName\"])\n",
    "                    column_8[\"Transaction_count\"].append(z[\"metric\"][\"count\"])\n",
    "                    column_8[\"Transaction_amount\"].append(z[\"metric\"][\"amount\"])\n",
    "                    column_8[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_8=pd.DataFrame(column_8)\n",
    "    df_8[\"State\"]=df_8[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_8[\"State\"]=df_8[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_8[\"State\"]=df_8[\"State\"].str.title()\n",
    "    df_8[\"State\"]=df_8[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_8\n",
    "\n",
    "def top_user_data():\n",
    "    path_9=\"D:\\\\capstone_project\\\\pulse_repo\\\\data\\\\top\\\\user\\\\country\\\\india\\\\state\\\\\"\n",
    "    column_9={'State':[],'Pincode':[],'Year':[],'quarter':[],'Registered_Users':[]}\n",
    "    for state in os.listdir(path_9):\n",
    "        for year in os.listdir(path_9+state+\"/\"):\n",
    "            for file in os.listdir(path_9+state+\"/\"+year+\"/\"):\n",
    "                data=open(path_9+state+\"/\"+year+\"/\"+file,\"r\")\n",
    "                D=json.load(data)\n",
    "                for z in D[\"data\"][\"pincodes\"]:\n",
    "                    column_9[\"State\"].append(state)\n",
    "                    column_9[\"Year\"].append(year)\n",
    "                    column_9[\"Pincode\"].append(z[\"name\"])\n",
    "                    column_9[\"Registered_Users\"].append(z[\"registeredUsers\"])\n",
    "                    column_9[\"quarter\"].append(int(file.strip(\".json\")))\n",
    "    df_9=pd.DataFrame(column_9)\n",
    "    df_9[\"State\"]=df_9[\"State\"].str.replace('andaman-&-nicobar-islands','andaman & nicobar')\n",
    "    df_9[\"State\"]=df_9[\"State\"].str.replace(\"-\",\" \")\n",
    "    df_9[\"State\"]=df_9[\"State\"].str.title()\n",
    "    df_9[\"State\"]=df_9[\"State\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "    return df_9\n",
    "\n",
    "# Run all extractors\n",
    "df_1, df_2, df_3, df_4, df_5, df_6,df_7,df_8,df_9 = agg_insur_data(),agg_trans_data(), agg_user_data(),map_insur_data(), map_trans_data(), map_user_data(), top_insur_data(),top_trans_data(), top_user_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connected to PostgreSQL\n",
      " New tables created successfully!\n"
     ]
    }
   ],
   "source": [
    "# 3. Connect to Render PostgreSQL\n",
    "load_dotenv()\n",
    "\n",
    "DB_HOST = os.getenv(\"RENDER_DB_HOST\")\n",
    "DB_PORT = os.getenv(\"RENDER_DB_PORT\")\n",
    "DB_NAME = os.getenv(\"RENDER_DB_NAME\")\n",
    "DB_USER = os.getenv(\"RENDER_DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"RENDER_DB_PASSWORD\")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD\n",
    ")\n",
    "cur = conn.cursor()\n",
    "print(\" Connected to PostgreSQL\")\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Create Tables (correct schema)\n",
    "# -----------------------------\n",
    "create_queries = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  agg_insur (\n",
    "        state TEXT,\n",
    "        year INT,\n",
    "        quarter TEXT,\n",
    "        transaction_type TEXT,\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount NUMERIC\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  agg_trans (\n",
    "        state TEXT,\n",
    "        year INT,\n",
    "        quarter TEXT,\n",
    "        transaction_type TEXT,\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount NUMERIC\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  agg_user (\n",
    "        state TEXT,\n",
    "        year INT,\n",
    "        quarter TEXT,\n",
    "        user_brand TEXT,\n",
    "        user_count BIGINT,\n",
    "        user_percentage NUMERIC\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  map_insur (\n",
    "        state TEXT,\n",
    "        year INT,\n",
    "        district TEXT,\n",
    "        quarter TEXT,\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount NUMERIC\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  map_trans (\n",
    "        state TEXT,\n",
    "        year INT,\n",
    "        district TEXT,\n",
    "        quarter TEXT,\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount NUMERIC\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  map_user (\n",
    "        state TEXT,\n",
    "        district TEXT,\n",
    "        year INT,\n",
    "        quarter TEXT,\n",
    "        registered_users BIGINT,\n",
    "        app_opens BIGINT\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  top_insur (\n",
    "        state TEXT,\n",
    "        pincode BIGINT,\n",
    "        year INT,\n",
    "        quarter TEXT,\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount NUMERIC\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  top_trans (\n",
    "        state TEXT,\n",
    "        pincode BIGINT,\n",
    "        year INT,\n",
    "        quarter TEXT,\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount NUMERIC\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS  top_user (\n",
    "        state TEXT,\n",
    "        pincode BIGINT,\n",
    "        year INT,\n",
    "        quarter TEXT,\n",
    "        registered_users BIGINT\n",
    "    )\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for query in create_queries:\n",
    "    cur.execute(query)\n",
    "conn.commit()\n",
    "print(\" New tables created successfully!\")\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f350216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inserted 682 rows into agg_insur\n",
      " Inserted 5034 rows into agg_trans\n",
      " Inserted 6732 rows into agg_user\n",
      " Inserted 13876 rows into map_insur\n",
      " Inserted 20604 rows into map_trans\n",
      " Inserted 20608 rows into map_user\n",
      " Inserted 6668 rows into top_insur\n",
      " Inserted 9999 rows into top_trans\n",
      " Inserted 10000 rows into top_user\n",
      "All DataFrames stored successfully in PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Insert Data into Tables\n",
    "# 6. Insert Function\n",
    "# -----------------------------\n",
    "def insert_dataframe_fast(df, table, cols):\n",
    "    # Ensure lowercase columns in DataFrame\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Convert DataFrame into list of tuples\n",
    "    values = [tuple(row[c] for c in cols) for _, row in df.iterrows()]\n",
    "\n",
    "    # Build SQL\n",
    "    sql = f\"INSERT INTO {table} ({','.join(cols)}) VALUES %s\"\n",
    "\n",
    "    # Bulk insert\n",
    "    execute_values(cur, sql, values, page_size=10000)\n",
    "    conn.commit()\n",
    "    print(f\" Inserted {len(df)} rows into {table}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Insert All DataFrames\n",
    "# -----------------------------\n",
    "insert_dataframe_fast(df_1, \"agg_insur\", [\"state\",\"year\",\"quarter\",\"transaction_type\",\"transaction_count\",\"transaction_amount\"])\n",
    "insert_dataframe_fast(df_2, \"agg_trans\", [\"state\",\"year\",\"quarter\",\"transaction_type\",\"transaction_count\",\"transaction_amount\"])\n",
    "insert_dataframe_fast(df_3, \"agg_user\", [\"state\",\"year\",\"quarter\",\"user_brand\",\"user_count\",\"user_percentage\"])\n",
    "insert_dataframe_fast(df_4, \"map_insur\", [\"state\",\"year\",\"district\",\"quarter\",\"transaction_count\",\"transaction_amount\"])\n",
    "insert_dataframe_fast(df_5, \"map_trans\", [\"state\",\"year\",\"district\",\"quarter\",\"transaction_count\",\"transaction_amount\"])\n",
    "insert_dataframe_fast(df_6, \"map_user\", [\"state\",\"district\",\"year\",\"quarter\",\"registered_users\",\"app_opens\"])\n",
    "insert_dataframe_fast(df_7, \"top_insur\", [\"state\",\"pincode\",\"year\",\"quarter\",\"transaction_count\",\"transaction_amount\"])\n",
    "insert_dataframe_fast(df_8, \"top_trans\", [\"state\",\"pincode\",\"year\",\"quarter\",\"transaction_count\",\"transaction_amount\"])\n",
    "insert_dataframe_fast(df_9, \"top_user\", [\"state\",\"pincode\",\"year\",\"quarter\",\"registered_users\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Close Connection\n",
    "# -----------------------------\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"All DataFrames stored successfully in PostgreSQL!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
